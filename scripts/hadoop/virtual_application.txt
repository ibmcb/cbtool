# Parameters for this Virtual Application (Application Instance - AI) type should
# be set on YOUR private configuration configuration file, including the ones 
# commented.

[AI_TEMPLATES : HADOOP]

# Attributes MANDATORY for all Virtual Applications
SUT = hadoopmaster->3_x_hadoopslave
LOAD_BALANCER_SUPPORTED = $False
RESIZE_SUPPORTED = $True
REGENERATE_DATA = $True
LOAD_GENERATOR_ROLE = hadoopmaster
LOAD_MANAGER_ROLE = hadoopmaster
METRIC_AGGREGATOR_ROLE = hadoopmaster
CAPTURE_ROLE = hadoopslave
LOAD_PROFILE = terasort
LOAD_LEVEL = uniformIXIXI1I3
LOAD_DURATION = 60
REPORTED_METRICS = throughput,latency,datagen_time,datagen_size

# VApp-specific MANDATORY attributes
DESCRIPTION = Deploys a Hadoop cluster (1 master and N slave nodes). The master
DESCRIPTION += node also runs the HiBench benchmark, which is used to submit
DESCRIPTION += hadoop jobs to the cluster.\n
DESCRIPTION +=- LOAD_PROFILE possible values: "sort", "wordcount", "terasort", 
DESCRIPTION += "dfsioe", "nutchindexing", "pagerank", "bayes", "kmeans", "hivebench" (for a proper
DESCRIPTION += description, consult the section "Overview" on the HiBench documentation)\n
DESCRIPTION +=- LOAD_LEVEL meaning: although the specifics vary by load profile,
DESCRIPTION += it basically represents "amount of data" generated and processed
DESCRIPTION += by the job.\n 
DESCRIPTION +=- LOAD_DURATION meaning: not used, a run ends when the hadoop job
DESCRIPTION += is completed.\n
DESCRIPTION +=- COMMENT: One of the "Big Data" Workloads. One of the two 
DESCRIPTION += Virtual Applications types selected for the SPECCloud 2014 v1.0 
DESCRIPTION += benchmark. When new slave nodes are added (after an "airesize")
DESCRIPTION += the Hadoop cluster is reconfigured to include these nodes.
HADOOPMASTER_SETUP1 = cb_config_hadoop_cluster.sh
HADOOPSLAVE_SETUP1 = cb_config_hadoop_cluster.sh
HADOOPMASTER_SETUP2 = cb_start_hadoop_cluster.sh
HADOOPSLAVE_SETUP2 = cb_start_hadoop_cluster.sh
HADOOPMASTER_RESIZE1 = cb_restart_hadoop_cluster.sh
HADOOPSLAVE_RESIZE1 = cb_restart_hadoop_cluster.sh
START = cb_hadoop_job.sh

# VApp-specific modifier parameters. Commented attributes imply default values assumed
JAVA_HOME = ~/jdk1.6.0_21
HADOOP_HOME = ~/hadoop-2.6.0
HADOOP_EXAMPLES = share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar
HIBENCH_HOME = ~/HiBench
DFS_NAME_DIR = /tmp/cbhadoopname
DFS_DATA_DIR = /tmp/cbhadoopdata
LOAD_FACTOR = 10000
CLASSES = 20
NUM_MAPS = 2
NUM_REDS = 2
NGRAMS = 3
RD_FILE_SIZE = 20
WT_FILE_SIZE = 10
NUM_OF_SAMPLES = 3000000
SAMPLES_PER_INPUTFILE = 500000
NUM_CLUSTERS = 5
DIMENSIONS = 20
MAX_ITERATION = 5
KMEANS_GENERATE_DATA = 1
BLOCK = 0
BLOCK_WIDTH = 16
ROWS_OF_BLOCKS=2
COLS_OF_BLOCKS=2
SEED_BASE=1234567890

# Inter-Virtual Application instances (inter-AI) synchronized execution. Entirely optional
#SYNC_COUNTER_NAME = synchronization_counter
#CONCURRENT_AIS = 2
#SYNC_CHANNEL_NAME = synchronization_channel
#RUN_COUNTER_NAME = experiment_id_counter